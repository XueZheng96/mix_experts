{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "from Models import GateCNNFahsionSoftmax, CNNFashion, GateCNNFashion\n",
    "from Util import FedAvg, Preparedata, Sample_node\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from Update import ClientUpdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_fashionmnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "dataset_train = datasets.FashionMNIST('../data/fashion-mnist', train=True, download = True, transform = trans_fashionmnist)\n",
    "dataset_test = datasets.FashionMNIST('../data/fashion-mnist',train=False, download = True, transform = trans_fashionmnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 4\n",
    "ntrain = 1000\n",
    "ntest = 300\n",
    "train_sets = []\n",
    "test_sets = []\n",
    "percent = 0.9\n",
    "#creat no-iid data\n",
    "# for i in range(num_clients):\n",
    "#     train_set, test_set = Preparedata(dataset_train, dataset_test, ntrain, ntest, class_number = [i%10], percent = percent)\n",
    "#     train_sets.append(train_set)\n",
    "#     test_sets.append(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = Preparedata(shuffle(dataset_train), dataset_test, ntrain, ntest, class_number = [0,1,2], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)\n",
    "\n",
    "\n",
    "# train_set, test_set = Preparedata(dataset_train, dataset_test, ntrain, ntest, class_number = [0,1,3], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)\n",
    "\n",
    "\n",
    "# train_set, test_set = Preparedata(shuffle(dataset_train), dataset_test, ntrain, ntest, class_number = [1,2,4], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)\n",
    "\n",
    "\n",
    "# train_set, test_set = Preparedata(dataset_train, dataset_test, ntrain, ntest, class_number = [0,1,3], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)\n",
    "\n",
    "\n",
    "# train_set, test_set = Preparedata(dataset_train, dataset_test, ntrain, ntest, class_number = [0,2,3], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = Preparedata(dataset_train, dataset_test, ntrain, ntest, class_number = [5,6,8], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)\n",
    "\n",
    "\n",
    "# train_set, test_set = Preparedata(shuffle(dataset_train), dataset_test, ntrain, ntest, class_number = [6,8,9], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)\n",
    "\n",
    "\n",
    "# train_set, test_set = Preparedata(dataset_train, dataset_test, ntrain, ntest, class_number = [7,8,9], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)\n",
    "\n",
    "\n",
    "# train_set, test_set = Preparedata(shuffle(dataset_train), dataset_test, ntrain, ntest, class_number = [5,6,8], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)\n",
    "\n",
    "\n",
    "# train_set, test_set = Preparedata(dataset_train, dataset_test, ntrain, ntest, class_number = [5,6,7], percent = percent)\n",
    "# train_sets.append(train_set)\n",
    "# test_sets.append(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "    def __init__(self, train_set=None,  test_set=None, idx=None):\n",
    "        \n",
    "        self.loss_func = nn.NLLLoss()\n",
    "        \n",
    "        self.train_set, self.val_set = torch.utils.data.random_split(train_set, [800, 200], torch.Generator().manual_seed(idx))\n",
    "\n",
    "        self.ldr_train = DataLoader(self.train_set, batch_size=10, shuffle=True)\n",
    "        self.ldr_val = DataLoader(self.val_set, batch_size = 1, shuffle=True)\n",
    "\n",
    "        self.test_set = test_set\n",
    "        self.ldr_test = DataLoader(self.test_set, batch_size = 1, shuffle=True)\n",
    "    \n",
    "    def train(self, net, n_epochs,learning_rate):\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(net.parameters(),lr=learning_rate)\n",
    "\n",
    "        epoch_loss = []\n",
    "\n",
    "        for iter in range(n_epochs):\n",
    "            net.train()\n",
    "            batch_loss = []\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                images, labels = (images, labels)\n",
    "                net.zero_grad()\n",
    "                log_probs = net(images.float())\n",
    "    \n",
    "                loss = self.loss_func(log_probs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                batch_loss.append(loss.item())\n",
    "                \n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "            \n",
    "#             val_acc, val_loss = self.validate(net,True)\n",
    "#             print(val_acc)\n",
    "\n",
    "        return net.state_dict(), epoch_loss[-1]\n",
    "   \n",
    "    \n",
    "    def train_finetune(self, net, n_epochs, learning_rate):\n",
    "        net.train()\n",
    "        \n",
    "        optimizer = torch.optim.Adam(net.parameters(),lr=learning_rate)\n",
    "        \n",
    "        patience = 10\n",
    "        epoch_loss = []\n",
    "        epoch_train_accuracy = []\n",
    "        model_best = net.state_dict()\n",
    "        train_acc_best = np.inf\n",
    "        val_acc_best = -np.inf\n",
    "        val_loss_best = np.inf\n",
    "        counter = 0\n",
    "        \n",
    "        for iter in range(n_epochs):\n",
    "            net.train()\n",
    "            batch_loss = []\n",
    "            correct = 0\n",
    "            \n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                images, labels = (images, labels)\n",
    "                net.zero_grad()\n",
    "                log_probs = net(images.float())\n",
    "                loss = self.loss_func(log_probs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_loss.append(loss.item())\n",
    "                _, predicted = torch.max(log_probs.data, 1)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            train_accuracy = 100.00 * correct / len(self.ldr_train.dataset)\n",
    "            epoch_train_accuracy.append(train_accuracy)\n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "            \n",
    "            if(iter%5==0):\n",
    "                val_acc, val_loss = self.validate(net,True)\n",
    "                net.train()\n",
    "                if(val_loss < val_loss_best - 0.01):\n",
    "                    counter = 0\n",
    "                    model_best = net.state_dict()\n",
    "                    val_acc_best = val_acc\n",
    "                    val_loss_best = val_loss\n",
    "                    train_acc_best = train_accuracy\n",
    "                    print(\"Iter: %d | %.2f\" %(iter,val_acc_best))\n",
    "                else:\n",
    "                    counter = counter+1\n",
    "                    \n",
    "                # early stop\n",
    "                if counter == patience:\n",
    "                    return model_best, epoch_loss[-1], val_acc_best, train_acc_best\n",
    "                    \n",
    "    \n",
    "        return model_best, epoch_loss[-1], val_acc_best, train_acc_best\n",
    "     \n",
    "        \n",
    "    def train_mix(self, net_local, net_trans, gate, train_gate_only, n_epochs, early_stop, learning_rate, val):\n",
    "\n",
    "        print(\"start train mix model\")        \n",
    "        gate.train()\n",
    "        net_local.train()\n",
    "        net_trans.train()\n",
    "\n",
    "        if(train_gate_only):\n",
    "            optimizer = torch.optim.Adam(gate.parameters(),lr=learning_rate)\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(list(gate.parameters())+list(net_local.parameters()),lr=learning_rate)\n",
    "\n",
    "      \n",
    "        patience = 30\n",
    "        epoch_loss = []\n",
    "        gate_best = gate.state_dict()\n",
    "        local_best = net_local.state_dict()\n",
    "        trans_best = net_trans.state_dict()\n",
    "        val_acc_best = -np.inf\n",
    "        val_loss_best = np.inf\n",
    "        counter = 0\n",
    "        gate_values_best = 0\n",
    "\n",
    "        \n",
    "        for iter in range(n_epochs):\n",
    "            net_local.train()\n",
    "            net_trans.train()\n",
    "            gate.train()\n",
    "\n",
    "            batch_loss = []\n",
    "\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                images, labels = (images, labels)\n",
    "\n",
    "                net_local.zero_grad()\n",
    "                net_trans.zero_grad()\n",
    "                gate.zero_grad()\n",
    "\n",
    "                gate_weight = gate(images.float())\n",
    "            \n",
    "\n",
    "                # gate_weight*wi + gate_weight*fintuned\n",
    "                local_prob = gate_weight*net_local(images.float())+(1-gate_weight)*net_trans(images.float())\n",
    "                loss = self.loss_func(local_prob,labels)\n",
    "  \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_loss.append(loss.item())\n",
    "\n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "            \n",
    "            \n",
    "            if(early_stop):\n",
    "                if(iter%5==0):\n",
    "                    val_acc, val_loss = self.validate_mix(net_local, net_trans, gate, val)\n",
    "                    net_local.train()\n",
    "                    net_trans.train()\n",
    "                    gate.train()\n",
    "\n",
    "                    if(val_loss < val_loss_best - 0.01):\n",
    "                        counter = 0\n",
    "                        gate_best = gate.state_dict()\n",
    "                        local_best = net_local.state_dict()\n",
    "                        trans_best = net_trans.state_dict()\n",
    "                        val_acc_best = val_acc\n",
    "                        val_loss_best = val_loss\n",
    "                        gate_weight_best = gate_weight\n",
    "                        print(\"Iter: %d | %.2f\" %(iter,val_acc_best))\n",
    "                    else:\n",
    "                        counter = counter + 1\n",
    "                        #print(counter)\n",
    "                \n",
    "                if counter == patience:\n",
    "                    return gate_best, local_best, trans_best, epoch_loss[-1],val_acc_best, sum(gate_weight_best) / len(gate_weight_best)\n",
    "\n",
    "\n",
    "        return gate_best, local_best, trans_best, epoch_loss[-1],val_acc_best, sum(gate_weight_best) / len(gate_weight_best)\n",
    "    \n",
    "        \n",
    "    def train_mix_clients(self, net_local, net_trans, net_clients, gate_frezze, gate, train_gate_only, n_epochs, early_stop, learning_rate, val):\n",
    "\n",
    "        print(\"start train mix model\")        \n",
    "        gate.train()\n",
    "        net_local.train()\n",
    "        net_trans.train()\n",
    "\n",
    "        if(train_gate_only):\n",
    "            optimizer = torch.optim.Adam(gate.parameters(),lr=learning_rate)\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam(list(gate.parameters())+list(net_local.parameters()),lr=learning_rate)\n",
    "\n",
    "      \n",
    "        patience = 30\n",
    "        epoch_loss = []\n",
    "        gate_best = gate.state_dict()\n",
    "        local_best = net_local.state_dict()\n",
    "        trans_best = net_trans.state_dict()\n",
    "        val_acc_best = -np.inf\n",
    "        val_loss_best = np.inf\n",
    "        counter = 0\n",
    "        gate_values_best = 0\n",
    "\n",
    "        \n",
    "        for iter in range(n_epochs):\n",
    "            net_local.train()\n",
    "            net_trans.train()\n",
    "            gate.train()\n",
    "\n",
    "            batch_loss = []\n",
    "\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                images, labels = (images, labels)\n",
    "\n",
    "                net_local.zero_grad()\n",
    "                net_trans.zero_grad()\n",
    "                gate.zero_grad()\n",
    "\n",
    "                gate_inner = gate_frezze(images.float())\n",
    "                gate_outer = gate(images.float())\n",
    "             \n",
    "\n",
    "                # gate_weight*wi + gate_weight*fintuned\n",
    "                local_prob_inner = gate_inner*net_local(images.float())+(1-gate_inner)*net_trans(images.float())\n",
    "                local_prob = gate_outer*net_clients(images.float())+(1-gate_outer)*local_prob_inner\n",
    "                loss = self.loss_func(local_prob,labels)\n",
    "  \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                batch_loss.append(loss.item())\n",
    "\n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "            \n",
    "            \n",
    "            if(early_stop):\n",
    "                if(iter%5==0):\n",
    "                    val_acc, val_loss = self.validate_mix_clients(net_local, net_trans, net_clients, gate_frezze, gate, val)\n",
    "                    net_local.train()\n",
    "                    net_trans.train()\n",
    "                    gate.train()\n",
    "\n",
    "                    if(val_loss < val_loss_best - 0.01):\n",
    "                        counter = 0\n",
    "                        gate_best = gate.state_dict()\n",
    "                        local_best = net_local.state_dict()\n",
    "                        trans_best = net_trans.state_dict()\n",
    "                        val_acc_best = val_acc\n",
    "                        val_loss_best = val_loss\n",
    "                        gate_weight_best = weight\n",
    "                        print(\"Iter: %d | %.2f\" %(iter,val_acc_best))\n",
    "                    else:\n",
    "                        counter = counter + 1\n",
    "                        #print(counter)\n",
    "                \n",
    "                if counter == patience:\n",
    "                    return gate_best, local_best, trans_best, epoch_loss[-1],val_acc_best, gate_weight_best\n",
    "\n",
    "\n",
    "        return gate_best, local_best, trans_best, epoch_loss[-1],val_acc_best, gate_outer\n",
    "    \n",
    "    \n",
    "    def validate(self,net,val):\n",
    "        # if true validate dataset, if false use test detaset\n",
    "        if(val):\n",
    "            dataloader = self.ldr_val\n",
    "        else:\n",
    "            dataloader = self.ldr_test\n",
    "       \n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            # validate\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            for idx, (data, target) in enumerate(dataloader):\n",
    "                data, target = (data, target)\n",
    "                log_probs = net(data.float())\n",
    "\n",
    "                val_loss += self.loss_func(log_probs, target).item()\n",
    "\n",
    "                y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
    "                correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
    "\n",
    "            val_loss /= len(dataloader.dataset)\n",
    "            accuracy = 100.00 * correct / len(dataloader.dataset)\n",
    "   \n",
    "        return accuracy.item(), val_loss\n",
    "    \n",
    "    def validate_mix(self, net_l, net_t, gate, val):\n",
    "        # if true validate dataset, if false use test detaset\n",
    "        if(val):\n",
    "            dataloader = self.ldr_val\n",
    "        else:\n",
    "            dataloader = self.ldr_test\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            net_l.eval()\n",
    "            net_t.eval()\n",
    "            gate.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            gate_values = np.array([])\n",
    "            label_values = np.array([])\n",
    "            \n",
    "            for idx, (data,target) in enumerate(dataloader):\n",
    "                data, target = (data,target)\n",
    "                gate_weight = gate(data.float())\n",
    "                \n",
    "                log_prob = gate_weight*net_l(data.float())+(1-gate_weight)*net_t(data.float())\n",
    "                \n",
    "\n",
    "                val_loss += self.loss_func(log_prob,target).item()\n",
    "                y_pred = log_prob.data.max(1,keepdim=True)[1]\n",
    "                correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
    "\n",
    "        val_loss /= len(dataloader.dataset)\n",
    "        accuracy = 100.00 * correct / len(dataloader.dataset)\n",
    "        return accuracy.item(), val_loss\n",
    "    \n",
    "    \n",
    "    \n",
    "    def validate_mix_clients(self, net_l, net_t, net_c, gate_f, gate, val):\n",
    "        # if true validate dataset, if false use test detaset\n",
    "        if(val):\n",
    "            dataloader = self.ldr_val\n",
    "        else:\n",
    "            dataloader = self.ldr_test\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            net_l.eval()\n",
    "            net_t.eval()\n",
    "            gate.eval()\n",
    "            net_c.eval()\n",
    "            val_loss = 0\n",
    "            correct = 0\n",
    "            gate_values = np.array([])\n",
    "            label_values = np.array([])\n",
    "            \n",
    "            for idx, (data,target) in enumerate(dataloader):\n",
    "                data, target = (data,target)\n",
    "                gate_inner = gate_f(data.float())\n",
    "                gate_outer = gate(data.float())\n",
    "                \n",
    "                local_prob_inner = gate_inner*net_l(data.float())+(1-gate_inner)*net_t(data.float())\n",
    "                log_prob = gate_outer*net_c(data.float())+(1-gate_outer)*local_prob_inner\n",
    "\n",
    "                val_loss += self.loss_func(log_prob,target).item()\n",
    "                y_pred = log_prob.data.max(1,keepdim=True)[1]\n",
    "                correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
    "\n",
    "        val_loss /= len(dataloader.dataset)\n",
    "        accuracy = 100.00 * correct / len(dataloader.dataset)\n",
    "        return accuracy.item(), val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initailize the probability_distribution\n",
    "probability_grapd = []\n",
    "for i in range (num_clients):\n",
    "    probability_grapd.append([1/(num_clients-1)]*(num_clients-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initailize the modle of every client\n",
    "net_glob_fedAvg = CNNFashion(num_classes)\n",
    "net_locals = [] # save the local model of every client\n",
    "\n",
    "for idx in range(num_clients):\n",
    "    net_local = CNNFashion(num_classes)\n",
    "    net_locals.append(net_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize all the gate_modle\n",
    "gate_models = []\n",
    "\n",
    "for idx in range(num_clients):\n",
    "    gate_model = GateCNNFashion()\n",
    "    gate_models.append(gate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize allclient\n",
    "# clients = []\n",
    "\n",
    "# for idx in range(num_clients):\n",
    "\n",
    "#     client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "#                                idx = idx)\n",
    "#     clients.append(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_ep = 200\n",
    "lr = 1e-4\n",
    "\n",
    "w_fedAvg = []\n",
    "alpha = []\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "w_clients = []\n",
    "net_fed = []\n",
    "val_local = []\n",
    "fintuned_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0\n",
      "Client 0\n",
      "86.0\n",
      "Client 1\n",
      "77.66666412353516\n",
      "Client 2\n",
      "87.0\n",
      "Client 3\n",
      "86.0\n",
      "Finetune 0\n",
      "Iter: 0 | 65.00\n",
      "Iter: 5 | 64.50\n",
      "Iter: 10 | 87.00\n",
      "Iter: 15 | 87.00\n",
      "Iter: 25 | 88.00\n",
      "85.66666412353516\n",
      "Finetune 1\n",
      "Iter: 0 | 2.00\n",
      "Iter: 5 | 59.50\n",
      "Iter: 10 | 63.00\n",
      "Iter: 20 | 66.00\n",
      "Iter: 25 | 72.00\n",
      "Iter: 30 | 75.00\n",
      "Iter: 35 | 74.50\n",
      "Iter: 40 | 76.50\n",
      "Iter: 50 | 77.00\n",
      "Iter: 65 | 77.50\n",
      "Iter: 90 | 79.00\n",
      "Iter: 125 | 80.50\n",
      "Iter: 175 | 80.50\n",
      "77.66666412353516\n",
      "Finetune 2\n",
      "Iter: 0 | 3.00\n",
      "Iter: 5 | 79.50\n",
      "Iter: 10 | 87.00\n",
      "Iter: 15 | 87.50\n",
      "88.0\n",
      "Finetune 3\n",
      "Iter: 0 | 2.50\n",
      "Iter: 5 | 76.00\n",
      "Iter: 10 | 82.00\n",
      "Iter: 15 | 83.00\n",
      "Iter: 20 | 85.00\n",
      "Iter: 30 | 86.50\n",
      "Iter: 75 | 86.50\n",
      "87.33333587646484\n",
      "[[2, 1], [2, 3], [3, 0], [0, 1]]\n",
      "Loop 1\n",
      "Client 0\n",
      "86.0\n",
      "Client 1\n",
      "77.66666412353516\n",
      "Client 2\n",
      "87.0\n",
      "Client 3\n",
      "86.0\n",
      "Finetune 0\n",
      "Iter: 0 | 57.50\n",
      "Iter: 5 | 57.50\n",
      "Iter: 10 | 82.00\n",
      "Iter: 15 | 82.50\n",
      "Iter: 25 | 82.50\n",
      "Iter: 50 | 84.00\n",
      "86.0\n",
      "Finetune 1\n",
      "Iter: 0 | 2.50\n",
      "Iter: 5 | 54.50\n",
      "Iter: 10 | 56.00\n",
      "Iter: 20 | 57.50\n",
      "60.33333206176758\n",
      "Finetune 2\n",
      "Iter: 0 | 5.50\n",
      "Iter: 5 | 83.50\n",
      "Iter: 10 | 84.00\n",
      "Iter: 20 | 84.00\n",
      "Iter: 55 | 86.00\n",
      "88.66666412353516\n",
      "Finetune 3\n",
      "Iter: 0 | 1.50\n",
      "Iter: 5 | 56.50\n",
      "Iter: 10 | 79.50\n",
      "Iter: 15 | 82.50\n",
      "Iter: 20 | 83.50\n",
      "Iter: 35 | 84.00\n",
      "Iter: 55 | 85.50\n",
      "Iter: 90 | 87.50\n",
      "86.33333587646484\n",
      "[[2, 1], [2, 3], [0, 1], [1, 0]]\n",
      "Loop 2\n",
      "Client 0\n",
      "86.0\n",
      "Client 1\n",
      "77.66666412353516\n",
      "Client 2\n",
      "87.0\n",
      "Client 3\n",
      "86.0\n",
      "Finetune 0\n",
      "Iter: 0 | 63.00\n",
      "Iter: 5 | 62.50\n",
      "Iter: 10 | 83.00\n",
      "Iter: 15 | 83.50\n",
      "Iter: 25 | 84.00\n",
      "Iter: 45 | 85.50\n",
      "Iter: 75 | 86.00\n",
      "86.0\n",
      "Finetune 1\n",
      "Iter: 0 | 2.50\n",
      "Iter: 5 | 53.50\n",
      "Iter: 10 | 61.00\n",
      "Iter: 15 | 61.50\n",
      "Iter: 20 | 69.50\n",
      "Iter: 25 | 74.50\n",
      "Iter: 30 | 75.50\n",
      "Iter: 35 | 76.50\n",
      "Iter: 45 | 77.00\n",
      "Iter: 60 | 78.50\n",
      "80.33333587646484\n",
      "Finetune 2\n",
      "Iter: 0 | 5.00\n",
      "Iter: 5 | 82.50\n",
      "Iter: 10 | 86.00\n",
      "Iter: 15 | 86.00\n",
      "Iter: 50 | 87.00\n",
      "Iter: 60 | 88.00\n",
      "90.0\n",
      "Finetune 3\n",
      "Iter: 0 | 59.00\n",
      "Iter: 5 | 58.50\n",
      "58.0\n",
      "[[3, 1], [3, 2], [0, 1], [0, 2]]\n",
      "Loop 3\n",
      "Client 0\n",
      "86.0\n",
      "Client 1\n",
      "77.66666412353516\n",
      "Client 2\n",
      "87.0\n",
      "Client 3\n",
      "86.0\n",
      "Finetune 0\n",
      "Iter: 0 | 60.50\n",
      "Iter: 5 | 60.50\n",
      "Iter: 10 | 83.00\n",
      "Iter: 15 | 85.50\n",
      "Iter: 20 | 85.50\n",
      "Iter: 35 | 86.50\n",
      "86.33333587646484\n",
      "Finetune 1\n",
      "Iter: 0 | 60.50\n",
      "Iter: 5 | 64.00\n",
      "Iter: 10 | 73.00\n",
      "Iter: 15 | 74.50\n",
      "Iter: 20 | 77.00\n",
      "Iter: 30 | 78.00\n",
      "Iter: 50 | 78.50\n",
      "Iter: 70 | 80.50\n",
      "79.33333587646484\n",
      "Finetune 2\n",
      "Iter: 0 | 3.00\n",
      "Iter: 5 | 83.00\n",
      "Iter: 10 | 86.00\n",
      "88.0\n",
      "Finetune 3\n",
      "Iter: 0 | 29.00\n",
      "Iter: 5 | 26.50\n",
      "Iter: 10 | 58.50\n",
      "Iter: 15 | 74.00\n",
      "Iter: 20 | 78.50\n",
      "Iter: 25 | 79.50\n",
      "Iter: 35 | 82.00\n",
      "Iter: 75 | 83.00\n",
      "84.66666412353516\n",
      "[[3, 1], [2, 3], [0, 1], [0, 2]]\n",
      "Loop 4\n",
      "Client 0\n",
      "86.0\n",
      "Client 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# update every client weight\n",
    "for ite in range(15):\n",
    "    train_sets = []\n",
    "    \n",
    "    train_set, test_set = Preparedata(shuffle(dataset_train), dataset_test, ntrain, ntest, class_number = [0,1,2], percent = percent)\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    train_set, test_set = Preparedata(shuffle(dataset_train), dataset_test, ntrain, ntest, class_number = [4,1,2], percent = percent)\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "    \n",
    "    train_set, test_set = Preparedata(shuffle(dataset_train), dataset_test, ntrain, ntest, class_number = [6,8,9], percent = percent)\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "    \n",
    "    train_set, test_set = Preparedata(shuffle(dataset_train), dataset_test, ntrain, ntest, class_number = [5,6,8], percent = percent)\n",
    "    train_sets.append(train_set)\n",
    "    test_sets.append(test_set)\n",
    "\n",
    "    \n",
    "    print(\"Loop %d\" %(ite))\n",
    "    #val_local = []\n",
    "    for idx in range(num_clients):\n",
    "        print(\"Client %d\" %(idx))\n",
    "        client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "                               idx = idx)\n",
    "\n",
    "        # trian the ith w\n",
    "        net_updated, train_loss_idx = client.train(net = net_locals[idx], n_epochs = 100,learning_rate = lr)\n",
    "\n",
    "        w_fedAvg.append(copy.deepcopy(net_updated))\n",
    "\n",
    "        net_locals[idx].load_state_dict(w_fedAvg[idx])\n",
    "\n",
    "        train_loss.append(train_loss_idx)\n",
    "\n",
    "        # envaluate the local nets\n",
    "        local_val_acc, val_loss = client.validate(net_locals[idx],False)\n",
    "        print(local_val_acc) \n",
    "        val_local.append(local_val_acc)\n",
    "\n",
    "\n",
    "\n",
    "    w_clients = []\n",
    "    if (ite == 0):\n",
    "        for idx  in range (num_clients):\n",
    "            w_clients.append(net_locals[idx].state_dict())\n",
    "    else: \n",
    "        for idx  in range (num_clients):\n",
    "            w_clients.append(fintuned_nets[idx].state_dict())\n",
    "\n",
    "\n",
    "    net_glob = []\n",
    "    fintuned_nets = []\n",
    "    selected_clients = []\n",
    "    #fintuned_acc = []\n",
    "\n",
    "    for idx in range(num_clients):\n",
    "        w =[]\n",
    "\n",
    "        list_of_candidates = list(range(0,num_clients))\n",
    "        list_of_candidates.remove(idx)\n",
    "\n",
    "        selected_client = Sample_node(2, idx, list_of_candidates, probability_grapd[idx])\n",
    "        #selected_client = [0,1,3,4]\n",
    "        # append selected clients for update the weight \n",
    "        selected_clients.append(selected_client)\n",
    "\n",
    "\n",
    "        for i in selected_client:\n",
    "             w.append(w_clients[i])\n",
    "\n",
    "        alpha = [1/len(selected_client)]*len(selected_client)\n",
    "\n",
    "        w_global = FedAvg(w,alpha)\n",
    "        net_glob_fedAvg.load_state_dict(w_global)\n",
    "        net_glob.append(net_glob_fedAvg)\n",
    "\n",
    "\n",
    "        print(\"Finetune %d\" %(idx))\n",
    "        # get the fituned w of other clients\n",
    "        client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "                                   idx = idx)\n",
    "        # model_best, epoch_loss[-1], val_acc_best, train_acc_best\n",
    "        net_w, train_loss_idx, val_acc_idx, train_acc_idx = client.train_finetune(net = net_glob_fedAvg, \n",
    "                                                n_epochs =200, learning_rate = 1e-4)\n",
    "\n",
    "        ft_net = copy.deepcopy(net_glob_fedAvg)\n",
    "        ft_net.load_state_dict(net_w)\n",
    "        fintuned_nets.append(ft_net)\n",
    "        #net_locals[idx] = ft_net\n",
    "        net_locals[idx] = fintuned_nets[idx]\n",
    "\n",
    "\n",
    "        fintuned_val_acc, val_loss = client.validate(ft_net,False)\n",
    "        fintuned_acc.append(fintuned_val_acc)\n",
    "        print(fintuned_val_acc)  \n",
    "\n",
    "    print(selected_clients)\n",
    "    plt.plot(val_local, 'r', fintuned_acc, 'b')\n",
    "    \n",
    "    for idx in range(num_clients):\n",
    "\n",
    "        if (val_local[idx+ite*num_clients] + 1 <= fintuned_acc[idx+ite*num_clients]):\n",
    "            # increase weight\n",
    "\n",
    "            for item in selected_clients[idx]:\n",
    "                if (item > idx):\n",
    "                    item = item-1\n",
    "                probability_grapd[idx][item] = probability_grapd[idx][item]*1.2\n",
    "        elif(val_local[idx+ite*num_clients] - 1 >= fintuned_acc[idx+ite*num_clients]):\n",
    "            for item in selected_clients[idx]:\n",
    "                if (item > idx):\n",
    "                    item = item-1\n",
    "                probability_grapd[idx][item] = probability_grapd[idx][item]*0.8\n",
    "\n",
    "        probability_grapd[idx] = [x / sum(probability_grapd[idx]) for x in probability_grapd[idx]]\n",
    "    # mix_fin_local_acc = []\n",
    "    # for idx in range(num_clients):\n",
    "    #     client = clients[idx]\n",
    "    #     client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "    #                                idx = idx)\n",
    "    #     gate_w, local_w, trans_w, epoch_loss, accuracy, weight = client.train_mix(net_locals[idx],fintuned_nets[idx],  \n",
    "    #                                          gate = gate_models[idx], train_gate_only = True, n_epochs =100, \n",
    "    #                                          early_stop=True, learning_rate = 5e-4, val = True)\n",
    "\n",
    "    #     gate_models[idx].load_state_dict(gate_w)\n",
    "    #     accuracy, val_loss = client.validate_mix(net_locals[idx],fintuned_nets[idx],gate_models[idx], False)\n",
    "    #     mix_fin_local_acc.append(accuracy)\n",
    "    #     print(accuracy)\n",
    "\n",
    "    #     net_locals[idx] = fintuned_nets[idx]\n",
    "\n",
    "\n",
    "\n",
    "    # plt.plot(val_local, 'r', fintuned_acc, 'b', mix_fin_local_acc, 'y')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_grapd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(num_clients):\n",
    "   \n",
    "    if (val_local[idx] < fintuned_acc[idx]):\n",
    "        # increase weight\n",
    "  \n",
    "        for item in selected_clients[idx]:\n",
    "            if (item > idx):\n",
    "                item = item-1\n",
    "            probability_grapd[idx][item] = probability_grapd[idx][item]*1.2\n",
    "    else:\n",
    "        for item in selected_clients[idx]:\n",
    "            if (item > idx):\n",
    "                item = item-1\n",
    "            probability_grapd[idx][item] = probability_grapd[idx][item]*0.8\n",
    "\n",
    "    probability_grapd[idx] = [x / sum(probability_grapd[idx]) for x in probability_grapd[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net_locals)\n",
    "print(fintuned_nets)\n",
    "# print(mix_fin_local_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_clients = []\n",
    "for idx  in range (num_clients):\n",
    "    w_clients.append(net_locals[idx].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune 0\n",
      "Iter: 0 | 65.00\n",
      "Iter: 5 | 65.00\n",
      "Iter: 10 | 67.00\n",
      "Iter: 15 | 69.50\n",
      "Iter: 25 | 68.00\n",
      "Iter: 40 | 70.00\n",
      "74.0\n",
      "Finetune 1\n",
      "Iter: 0 | 74.50\n",
      "Iter: 5 | 75.50\n",
      "Iter: 10 | 75.50\n",
      "Iter: 15 | 74.00\n",
      "Iter: 20 | 74.50\n",
      "Iter: 35 | 75.00\n",
      "Iter: 50 | 76.50\n",
      "Iter: 75 | 77.00\n",
      "Iter: 95 | 79.00\n",
      "77.33333587646484\n",
      "Finetune 2\n",
      "Iter: 0 | 66.00\n",
      "Iter: 5 | 66.50\n",
      "Iter: 10 | 67.50\n",
      "Iter: 15 | 68.50\n",
      "Iter: 25 | 70.00\n",
      "Iter: 35 | 73.00\n",
      "Iter: 60 | 74.50\n",
      "Iter: 80 | 75.00\n",
      "Iter: 90 | 76.00\n",
      "Iter: 125 | 77.50\n",
      "77.0\n",
      "Finetune 3\n",
      "Iter: 0 | 70.50\n",
      "Iter: 5 | 69.50\n",
      "Iter: 10 | 76.50\n",
      "Iter: 15 | 77.50\n",
      "Iter: 20 | 76.50\n",
      "Iter: 30 | 79.50\n",
      "Iter: 45 | 79.50\n",
      "Iter: 75 | 80.00\n",
      "79.33333587646484\n",
      "Finetune 4\n",
      "Iter: 0 | 66.00\n",
      "Iter: 5 | 65.50\n",
      "Iter: 10 | 68.50\n",
      "Iter: 15 | 70.00\n",
      "Iter: 30 | 70.00\n",
      "Iter: 60 | 70.50\n",
      "79.66666412353516\n",
      "Finetune 5\n",
      "Iter: 0 | 64.00\n",
      "Iter: 5 | 68.50\n",
      "Iter: 10 | 73.50\n",
      "Iter: 15 | 73.50\n",
      "Iter: 25 | 75.00\n",
      "Iter: 35 | 73.50\n",
      "Iter: 60 | 76.00\n",
      "75.33333587646484\n",
      "Finetune 6\n",
      "Iter: 0 | 56.50\n",
      "Iter: 5 | 57.00\n",
      "Iter: 10 | 57.50\n",
      "Iter: 15 | 57.50\n",
      "Iter: 20 | 61.50\n",
      "Iter: 30 | 62.00\n",
      "Iter: 35 | 63.00\n",
      "Iter: 55 | 69.00\n",
      "Iter: 65 | 70.50\n",
      "Iter: 100 | 70.50\n",
      "Iter: 105 | 72.50\n",
      "73.0\n",
      "Finetune 7\n",
      "Iter: 0 | 72.50\n",
      "Iter: 5 | 73.50\n",
      "Iter: 10 | 74.50\n",
      "Iter: 15 | 74.50\n",
      "Iter: 25 | 75.50\n",
      "Iter: 40 | 76.00\n",
      "Iter: 65 | 77.00\n",
      "Iter: 115 | 78.50\n",
      "Iter: 140 | 80.50\n",
      "77.33333587646484\n",
      "Finetune 8\n",
      "Iter: 0 | 32.50\n",
      "Iter: 5 | 46.00\n",
      "Iter: 10 | 53.00\n",
      "Iter: 15 | 56.50\n",
      "Iter: 20 | 58.50\n",
      "Iter: 25 | 59.50\n",
      "Iter: 30 | 61.00\n",
      "Iter: 35 | 61.50\n",
      "Iter: 55 | 63.00\n",
      "Iter: 60 | 66.50\n",
      "Iter: 70 | 67.00\n",
      "Iter: 105 | 69.50\n",
      "68.66666412353516\n",
      "Finetune 9\n",
      "Iter: 0 | 18.50\n",
      "Iter: 5 | 28.00\n",
      "Iter: 10 | 47.50\n",
      "Iter: 15 | 51.00\n",
      "Iter: 20 | 52.50\n",
      "Iter: 30 | 53.00\n",
      "Iter: 50 | 55.00\n",
      "Iter: 70 | 55.50\n",
      "Iter: 95 | 63.00\n",
      "Iter: 115 | 64.00\n",
      "Iter: 145 | 63.50\n",
      "65.0\n"
     ]
    }
   ],
   "source": [
    "net_glob = []\n",
    "fintuned_nets = []\n",
    "selected_clients = []\n",
    "Fintuned_acc = []\n",
    "\n",
    "for idx in range(num_clients):\n",
    "    \n",
    "    \n",
    "    w =[]\n",
    "\n",
    "    list_of_candidates = list(range(0,num_clients))\n",
    "    list_of_candidates.remove(idx)\n",
    "\n",
    "    selected_client = Sample_node(2, idx, list_of_candidates, probability_grapd[idx])\n",
    "    #selected_client = [0,1,3,4]\n",
    "    # append selected clients for update the weight \n",
    "    selected_clients.append(selected_client)\n",
    "   \n",
    "\n",
    "    for i in selected_client:\n",
    "         w.append(w_clients[i])\n",
    "\n",
    "    alpha = [1/len(selected_client)]*len(selected_client)\n",
    "\n",
    "    w_global = FedAvg(w,alpha)\n",
    "    net_glob_fedAvg.load_state_dict(w_global)\n",
    "    net_glob.append(net_glob_fedAvg)\n",
    "\n",
    "\n",
    "    print(\"Finetune %d\" %(idx))\n",
    "    # get the fituned w of other clients\n",
    "    client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "                               idx = idx)\n",
    "    # model_best, epoch_loss[-1], val_acc_best, train_acc_best\n",
    "    net_w, train_loss_idx, val_acc_idx, train_acc_idx = client.train_finetune(net = net_glob_fedAvg, \n",
    "                                            n_epochs =200, learning_rate = 1e-4)\n",
    "\n",
    "    ft_net = copy.deepcopy(net_glob_fedAvg)\n",
    "    ft_net.load_state_dict(net_w)\n",
    "    fintuned_nets.append(ft_net)\n",
    "\n",
    "\n",
    "    val_acc, val_loss = client.validate(ft_net,False)\n",
    "    Fintuned_acc.append(val_acc)\n",
    "    print(val_acc)  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 4], [2, 4], [4, 0], [0, 4], [0, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(selected_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_glob = []\n",
    "# fintuned_nets = []\n",
    "# # the fedavg of every client\n",
    "# for idx in range(num_clients):\n",
    "#     w =[]\n",
    "    \n",
    "#     for i in range(num_clients):\n",
    "#         if i != idx:\n",
    "#             w.append(w_clients[i])\n",
    "            \n",
    "#     alpha = [1/(num_clients-1)]*(num_clients-1)\n",
    "     \n",
    "#     w_global = FedAvg(w,alpha)\n",
    "#     net_glob_fedAvg.load_state_dict(w_global)\n",
    "#     net_glob.append(net_glob_fedAvg)\n",
    "    \n",
    "#     print(\"Finetune %d\" %(idx))\n",
    "#     # get the fituned w of other clients\n",
    "#     client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "#                                idx = idx)\n",
    "#     # model_best, epoch_loss[-1], val_acc_best, train_acc_best\n",
    "#     net_w, train_loss_idx, val_acc_idx, train_acc_idx = client.train_finetune(net = net_glob_fedAvg, \n",
    "#                                             n_epochs =150, learning_rate = 1e-4)\n",
    "\n",
    "#     ft_net = copy.deepcopy(net_glob_fedAvg)\n",
    "#     ft_net.load_state_dict(net_w)\n",
    "#     fintuned_nets.append(ft_net)\n",
    "\n",
    "#     val_acc, val_loss = client.validate(ft_net,False)\n",
    "#     print(val_acc)  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize all the gate_modle\n",
    "gate_models = []\n",
    "for idx in range(num_clients):\n",
    "    gate_model = GateCNNFashion()\n",
    "    gate_models.append(gate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train mix model\n",
      "Iter: 0 | 67.50\n",
      "73.33333587646484\n",
      "start train mix model\n",
      "Iter: 0 | 64.00\n",
      "Iter: 5 | 79.50\n",
      "82.0\n",
      "start train mix model\n",
      "Iter: 0 | 75.00\n",
      "Iter: 5 | 77.00\n",
      "Iter: 45 | 77.50\n",
      "78.66666412353516\n",
      "start train mix model\n",
      "Iter: 0 | 80.50\n",
      "78.0\n",
      "start train mix model\n",
      "Iter: 0 | 67.50\n",
      "70.0\n"
     ]
    }
   ],
   "source": [
    "mix_fin_local_acc = []\n",
    "for idx in range(num_clients):\n",
    "    client = clients[idx]\n",
    "    client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "                               idx = idx)\n",
    "    gate_w, local_w, trans_w, epoch_loss, accuracy, weight = client.train_mix(net_locals[idx],fintuned_nets[idx],  \n",
    "                                         gate = gate_models[idx], train_gate_only = True, n_epochs =200, \n",
    "                                         early_stop=True, learning_rate = 5e-4, val = True)\n",
    "    \n",
    "    gate_models[idx].load_state_dict(gate_w)\n",
    "    accuracy, val_loss = client.validate_mix(net_locals[idx],fintuned_nets[idx],gate_models[idx], False)\n",
    "    mix_fin_local_acc.append(accuracy)\n",
    "    print(accuracy)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff75f79e280>,\n",
       " <matplotlib.lines.Line2D at 0x7ff75f79e2b0>,\n",
       " <matplotlib.lines.Line2D at 0x7ff75f79e370>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(val_local, 'r', fintuned_acc, 'b', Mix_fin_local_acc, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gate_models_ll = []\n",
    "\n",
    "# for idx in range(num_clients):\n",
    "#     gate_model = GateCNNFashion()\n",
    "#     gate_models_ll.append(gate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train node 0  with node 8 \n",
      "start train mix model\n",
      "Iter: 0 | 74.33\n",
      "Iter: 25 | 76.33\n",
      "train node 0  with node 5 \n",
      "start train mix model\n",
      "Iter: 0 | 73.67\n"
     ]
    }
   ],
   "source": [
    "gate_graph = []\n",
    "\n",
    "for idx in range(num_clients):    \n",
    "    gate = []\n",
    "    loss = []\n",
    "    acc = []\n",
    "    #client = clients[idx]\n",
    "    for i in selected_clients[idx]:\n",
    "        print(\"train node %d  with node %d \"%(idx,i))\n",
    "        client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "                               idx = idx)\n",
    "        gate_w, local_w, trans_w, epoch_loss, accuracy, weight = client.train_mix_clients(net_locals[idx],fintuned_nets[idx], net_locals[i], gate_models[idx],\n",
    "                                                                                  gate = GateCNNFashion(), train_gate_only = True, n_epochs =100, \n",
    "                                                                                  early_stop=True, learning_rate = 5e-4, val = False)\n",
    "\n",
    "        \n",
    "        gate.append(float(sum(weight)/len(weight)))\n",
    "    \n",
    "    gate_graph.append(gate)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "                               idx = idx)\n",
    "net_w, train_loss_idx, val_acc_idx, train_acc_idx = client.train_finetune(net = net_locals[2], \n",
    "                                            n_epochs =200, learning_rate = 1e-3)\n",
    "print(train_acc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "                               idx = idx)\n",
    "net_w, train_loss_idx, val_acc_idx, train_acc_idx = client.train_finetune(net = net_locals[0], \n",
    "                                            n_epochs =200, learning_rate = 1e-3)\n",
    "print(train_acc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "client = ClientUpdate(train_set=train_sets[idx], test_set = test_sets[idx],\n",
    "                               idx = idx)\n",
    "net_w, train_loss_idx, val_acc_idx, train_acc_idx = client.train_finetune(net = net_locals[2], \n",
    "                                            n_epochs =200, learning_rate = 1e-4)\n",
    "print(train_acc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
